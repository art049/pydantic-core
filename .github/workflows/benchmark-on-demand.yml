name: benchmark-on-demand

on:
  workflow_dispatch:
    inputs:
      commit:
        description: 'Commit to benchmark'
        type: string
        required: true

permissions:
  deployments: write
  contents: write

jobs:
  benchmarks:
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: "Checkout an older revision"
        run: git reset --hard ${{ inputs.commit }}

      - uses: actions/setup-python@v3
        with:
          python-version: '3.10.5'

      - uses: actions/cache@v2
        id: cache-py
        name: cache python
        with:
          path: ${{ env.pythonLocation }}
          key: >
            py
            ${{ env.pythonLocation }}
            ${{ hashFiles('tests/requirements.txt') }}
            ${{ hashFiles('pyproject.toml') }}

      - run: pip install -r tests/requirements.txt
        if: steps.cache-py.outputs.cache-hit != 'true'

      - name: install rust
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal

      - name: cache rust
        uses: Swatinem/rust-cache@v1

      - run: pip install . -v

      # this is required so that pytest uses the installed package
      - run: rm tests/__init__.py

      - run: >
          pytest tests/benchmarks/
          --benchmark-enable
          --benchmark-save output

      - name: Upload benchmark data to Avalanche
        run: |
          BENCH_FILE=$(find .benchmarks -type f)
          curl -X POST -H "Content-Type: application/json" -H "Authorization: ${{ secrets.AVALANCHE_KEY }}" -d @$BENCH_FILE https://avalanche-api.vercel.app/api/upload
